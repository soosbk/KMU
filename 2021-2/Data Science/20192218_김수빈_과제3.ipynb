{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20192218_김수빈_과제3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HHD-XtYJez-"
      },
      "source": [
        " **Pytorch로 Softmax Regression 구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPm-Uvx2yGUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af51240b-5f6a-4d2b-f306-8f24d5f0c2f8"
      },
      "source": [
        "#학습 데이터 생성\n",
        "import torch\n",
        "\n",
        "x_train=torch.FloatTensor([[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]])\n",
        "y_train=torch.FloatTensor([[0,0,1],[0,0,1],[0,0,1],[0,1,0],[0,1,0],[0,1,0],[1,0,0],[1,0,0]])\n",
        "\n",
        "#w,b 초기화\n",
        "#optimizer 생성하기\n",
        "\n",
        "w=torch.zeros(4,3,requires_grad=True)\n",
        "b=torch.zeros(1,3,requires_grad=True)\n",
        "\n",
        "optimizer=torch.optim.Adam([w,b],lr=0.1)\n",
        "\n",
        "#반복횟수 설정\n",
        "#가설 및 비용 설정하기\n",
        "for epoch in range(3001):\n",
        "  hypothesis=torch.softmax(torch.mm(x_train,w)+b,dim=1) #  hypothesis=torch.softmax(torch.mm(x_train,w)+b,dim=1)\n",
        "  cost=-torch.mean(torch.sum(y_train*torch.log(hypothesis),dim=1)) # cost=-torch.mean(torch.sum(y_train*torch.log(hypothesis),dim=1))\n",
        "\n",
        "\n",
        "  #optimizer 를 이용한 경사 계산 및 w, b 업데이트\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  #학습이 잘 되었는지 확인하기 위한 내용 출력\n",
        "  if epoch%300 ==0:\n",
        "    print(\"epoch: {},cost: {:.6f}\".format(epoch,cost.item()))\n",
        "\n",
        "\n",
        "# x가 [1,11,10,9],[1,3,4,3],[1,1,0,1]일 때, y값은?\n",
        "print(\"\\nx가 [1,11,10,9],[1,3,4,3],[1,1,0,1]일 때, y값은?\\n\")\n",
        "w.requires_grad_(False)\n",
        "b.requires_grad_(False)\n",
        "\n",
        "x_test=torch.FloatTensor([[1,11,10,9],[1,3,4,3],[1,1,0,1]])\n",
        "test_all=torch.softmax(torch.mm(x_test,w)+b,dim=1)\n",
        "print(test_all)\n",
        "print(torch.argmax(test_all,dim=1))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0,cost: 1.098612\n",
            "epoch: 300,cost: 0.105262\n",
            "epoch: 600,cost: 0.042634\n",
            "epoch: 900,cost: 0.023111\n",
            "epoch: 1200,cost: 0.014479\n",
            "epoch: 1500,cost: 0.009879\n",
            "epoch: 1800,cost: 0.007124\n",
            "epoch: 2100,cost: 0.005338\n",
            "epoch: 2400,cost: 0.004113\n",
            "epoch: 2700,cost: 0.003236\n",
            "epoch: 3000,cost: 0.002588\n",
            "\n",
            "x가 [1,11,10,9],[1,3,4,3],[1,1,0,1]일 때, y값은?\n",
            "\n",
            "tensor([[1.0000e+00, 5.5165e-19, 7.0151e-38],\n",
            "        [1.4800e-02, 7.4294e-01, 2.4226e-01],\n",
            "        [1.2256e-33, 9.0835e-12, 1.0000e+00]])\n",
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Zqg-8XJ4ck"
      },
      "source": [
        "**조금 더 깔끔하게 Softmax** ->cross_entropy를 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrsTF3dKPqWD",
        "outputId": "62ceff7f-595e-46a9-82f3-6b062543a70b"
      },
      "source": [
        "#학습 데이터 생성\n",
        "#torch.nn.functional을 F라는 이름으로 사용하겠다고 선언 \n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "x_train=torch.FloatTensor([[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]])\n",
        "y_train=torch.LongTensor([2,2,2,1,1,1,0,0]) #y_train수정\n",
        "\n",
        "#w,b 초기화\n",
        "#optimizer 생성하기\n",
        "\n",
        "w=torch.zeros(4,3,requires_grad=True)\n",
        "b=torch.zeros(1,3,requires_grad=True)\n",
        "\n",
        "optimizer=torch.optim.Adam([w,b],lr=0.1)\n",
        "\n",
        "#반복횟수 설정\n",
        "#가설 및 비용 수정하기\n",
        "for epoch in range(3001):\n",
        "  z=torch.mm(x_train,w)+b\n",
        "  cost=F.cross_entropy(z,y_train) #F.cross_entropy = softmax+ cross_entropy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer 를 이용한 경사 계산 및 w, b 업데이트\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  #학습이 잘 되었는지 확인하기 위한 내용 출력\n",
        "  if epoch%300 ==0:\n",
        "    print(\"epoch: {},cost: {:.6f}\".format(epoch,cost.item()))\n",
        "\n",
        "\n",
        "\n",
        "# x가 [1,11,10,9],[1,3,4,3],[1,1,0,1]일 때, y값은?\n",
        "print(\"\\nx가 [1,11,10,9],[1,3,4,3],[1,1,0,1]일 때, y값은?\\n\")\n",
        "w.requires_grad_(False)\n",
        "b.requires_grad_(False)\n",
        "\n",
        "x_test=torch.FloatTensor([[1,11,10,9],[1,3,4,3],[1,1,0,1]])\n",
        "test_all=torch.softmax(torch.mm(x_test,w)+b,dim=1)\n",
        "print(test_all)\n",
        "print(torch.argmax(test_all,dim=1))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0,cost: 1.098612\n",
            "epoch: 300,cost: 0.105263\n",
            "epoch: 600,cost: 0.042634\n",
            "epoch: 900,cost: 0.023111\n",
            "epoch: 1200,cost: 0.014479\n",
            "epoch: 1500,cost: 0.009879\n",
            "epoch: 1800,cost: 0.007124\n",
            "epoch: 2100,cost: 0.005338\n",
            "epoch: 2400,cost: 0.004113\n",
            "epoch: 2700,cost: 0.003236\n",
            "epoch: 3000,cost: 0.002588\n",
            "\n",
            "x가 [1,11,10,9],[1,3,4,3],[1,1,0,1]일 때, y값은?\n",
            "\n",
            "tensor([[1.0000e+00, 5.5164e-19, 7.0151e-38],\n",
            "        [1.4799e-02, 7.4294e-01, 2.4226e-01],\n",
            "        [1.2256e-33, 9.0836e-12, 1.0000e+00]])\n",
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OapyJbiYTgGo",
        "outputId": "a5a20f80-8c8a-43ca-9152-a06f22b49384"
      },
      "source": [
        "#w와 b를 nn.Linear로 대체하는 부분\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F #torch.nn.functional을 F라는 이름으로 사용하겠다고 선언 \n",
        "import torch.nn as nn\n",
        "\n",
        "x_train=torch.FloatTensor([[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]])\n",
        "y_train=torch.LongTensor([2,2,2,1,1,1,0,0]) #y_train수정\n",
        "\n",
        "#w와 b를 nn.Linear로 대체하기\n",
        "model=nn.Linear(4,3)\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=1)\n",
        "\n",
        "#반복횟수 설정\n",
        "#가설 및 비용 수정하기\n",
        "for epoch in range(3001):\n",
        "  z=model(x_train)\n",
        "  cost=F.cross_entropy(z,y_train) #F.cross_entropy = softmax+ cross_entropy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #optimizer 를 이용한 경사 계산 및 w, b 업데이트\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  #학습이 잘 되었는지 확인하기 위한 내용 출력\n",
        "  if epoch%300 ==0:\n",
        "    print(\"epoch: {},cost: {:.6f}\".format(epoch,cost.item()))\n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0,cost: 2.340644\n",
            "epoch: 300,cost: 0.028330\n",
            "epoch: 600,cost: 0.011371\n",
            "epoch: 900,cost: 0.006160\n",
            "epoch: 1200,cost: 0.003869\n",
            "epoch: 1500,cost: 0.002647\n",
            "epoch: 1800,cost: 0.001914\n",
            "epoch: 2100,cost: 0.001437\n",
            "epoch: 2400,cost: 0.001109\n",
            "epoch: 2700,cost: 0.000874\n",
            "epoch: 3000,cost: 0.000700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYhULt9fMoSI"
      },
      "source": [
        "Softmax Regression with Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSXTgVGFMsBj",
        "outputId": "78a6d0fa-f5df-4a80-d6f7-9f063b6a4e14"
      },
      "source": [
        "#y에 두 종류 이상의 값이 있을 경우 softmax regression 실행\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x_train=np.array([[1,2,1,1],[2,1,3,2],[3,1,3,4],[4,1,5,5],[1,7,5,5],[1,2,5,6],[1,6,6,6],[1,7,7,7]])\n",
        "\n",
        "#y에 0,1,2등 둘 이상의 class가 존재 => softmax regression\n",
        "y_train=np.array([2,2,2,1,1,1,0,0])\n",
        "\n",
        "logistic=LogisticRegression() #모델 생성\n",
        "logistic.fit(x_train,y_train) #학습\n",
        "\n",
        "#값예측\n",
        "pred=logistic.predict([[1,11,10,9],[1,3,4,3],[1,1,0,1]]) #test case\n",
        "print(pred) #출력"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 2]\n"
          ]
        }
      ]
    }
  ]
}